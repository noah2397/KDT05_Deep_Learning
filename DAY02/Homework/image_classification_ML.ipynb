{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathn\\.conda\\envs\\Torch_PY38\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', as_frame=True) # 숫자 데이터를 사용할 것임\n",
    "import pandas as pd\n",
    "mnist.frame.to_csv(\"num.csv\", index=False)\n",
    "targetDF=mnist.target\n",
    "targetDF=targetDF.astype('int') # int로 타입 변경\n",
    "targetDF.to_csv(\"ans.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDF=pd.read_csv(\"num.csv\")/255 # MinMax 스케일러 적용\n",
    "targetDF=pd.read_csv(\"ans.csv\")[\"class\"] # Series 형태로 뽑음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (60000, 785), y_train : (60000,)\n",
      "x_test : (10000, 785), y_test : (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train=featureDF.iloc[:60000]\n",
    "y_train=targetDF.iloc[:60000]\n",
    "x_test=featureDF.iloc[60000:]\n",
    "y_test=targetDF.iloc[60000:]\n",
    "print(f\"x_train : {x_train.shape}, y_train : {y_train.shape}\")\n",
    "print(f\"x_test : {x_test.shape}, y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train : (42000, 785), y_train : (42000,)\n",
      "x_val : (18000, 785), y_val : (18000,)\n"
     ]
    }
   ],
   "source": [
    "# 학습용 & 검증용 분리 => 학습용 데이터셋에서 일부를 검증용으로 준비\n",
    "# 검증용 : 학습 시 모델 최적화가 잘 되는지 검사하는 데이터셋\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3,stratify=y_train,random_state=5)\n",
    "print(f\"x_train : {x_train.shape}, y_train : {y_train.shape}\")\n",
    "print(f\"x_val : {x_val.shape}, y_val : {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score : 0.9449285714285715, test_score:0.9195\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "# 분류 방법 : Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model=LogisticRegression(max_iter=10000)\n",
    "lr_model.fit(x_train,y_train)\n",
    "train_score=lr_model.score(x_train,y_train)\n",
    "test_score=lr_model.score(x_val, y_val)\n",
    "print(f'train_score : {train_score}, test_score:{test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score : 0.9193095238095238, test_score:0.9086666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# Logistic Regression 알고리즘으로 학습 진행\n",
    "lr_sgd=SGDClassifier(loss=\"log_loss\", random_state=5)\n",
    "lr_sgd.fit(x_train,y_train)\n",
    "train_score=lr_sgd.score(x_train,y_train)\n",
    "test_score=lr_sgd.score(x_val, y_val)\n",
    "print(f'train_score : {train_score}, test_score:{test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import torch   \n",
    "import torch.nn as nn              \n",
    "import torch.nn.functional as F       \n",
    "import torch.optim as optim     \n",
    "\n",
    "def load_image(filename, start, end):\n",
    "    tensor_list=[]\n",
    "    for i in range(start,end+1):\n",
    "        img_data=torch.tensor(imageio.imread(f\"./img/{filename}{i}.png\"))\n",
    "        new_size = (100, 100)\n",
    "        resized_img_data = F.interpolate(img_data.unsqueeze(0).permute(0, 3, 1, 2), size=new_size, mode='bilinear', align_corners=False)\n",
    "        resized_img_data = resized_img_data.squeeze(0).permute(1, 2, 0)\n",
    "        tensor_list.append(resized_img_data)\n",
    "    return torch.stack(tensor_list)\n",
    "\n",
    "sento=load_image(\"sento\",0,19)\n",
    "why=load_image(\"why\",0,12)\n",
    "x = torch.cat([sento, why], dim=0) # 사진 33개, shape : [33,100,100,4]\n",
    "x=x.float()\n",
    "y = [0 for _ in range(20)]+[1 for _ in range(13)] # 0 : 전투방, 1: 비밀방 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.reshape(33,40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score : 1.0\n"
     ]
    }
   ],
   "source": [
    "lr_sgd.fit(x,y)\n",
    "train_score=lr_sgd.score(x,y)\n",
    "print(f'train_score : {train_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
